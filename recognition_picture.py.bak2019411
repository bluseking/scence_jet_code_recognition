from __future__ import print_function
import numpy as np
import sys,os
import os.path
import itertools
from collections import OrderedDict
import time 
import multiprocessing
import threading
import zmq
import params

sys.path.append(os.getcwd())

import torch
from  torch.autograd import Variable
import utils
import dataset
from PIL import Image
import models.crnn as crnn
import alphabets
from io import BytesIO

str1 = alphabets.alphabet

HEARTBEAT_LIVENESS = 3
HEARTBEAT_INTERVAL = 1.0
INTERVAL_INIT = 1
INTERVAL_MAX = 32

PPP_READY = b"\x01"
PPP_HEARTBEAT = b"\x02"

NBR_WORKERS = 10

crnn_model_path = '/home/cad488/crnn_scene_recognition_kinds_36/expr/crnn_no_IO_4_56371.pth'
FRONTEND_HOST = "tcp://*:5678"
BACKEND_HOST= "tcp://*:5679"

print(FRONTEND_HOST)

alphabet = str1
nclass = len(alphabet)+1
model = None
# crnn文本信息识别
def crnn_recognition(cropped_image, model):

    converter = utils.strLabelConverter(alphabet)
  
    image = cropped_image.convert('L')

    ## 
    w = int(image.size[0] / (280 * 1.0 / params.imgW))
    transformer = dataset.resizeNormalize((w, 32))
    image = transformer(image)
    #if torch.cuda.is_available():
        #image = image.cuda()
    image = image.view(1, *image.size())
    image = Variable(image)

    model.eval()
    preds = model(image)

    _, preds = preds.max(2)
    preds = preds.transpose(1, 0).contiguous().view(-1)

    preds_size = Variable(torch.IntTensor([preds.size(0)]))
    #raw_pred = converter.decode(preds.data, preds_size.data, raw=True)
    sim_pred = converter.decode(preds.data, preds_size.data, raw=False)
    #print('%-20s => %-20s' % (raw_pred, sim_preda
    print('result:{0}'.format(sim_pred))
    return ('{0}'.format(sim_pred))


class Worker(object):
    def __init__(self, address):
        self.address = address
        self.expiry = time.time() + HEARTBEAT_INTERVAL * HEARTBEAT_LIVENESS

class WorkerQueue(object):
    def __init__(self):
        self.queue = OrderedDict()

    def ready(self, worker):
        self.queue.pop(worker.address, None)
        self.queue[worker.address] = worker

    def purge(self):
        """Look for & kill expired workers."""
        t = time.time()
        expired = []
        for address,worker in self.queue.items():
            if t > worker.expiry:  # Worker expired
                expired.append(address)
        for address in expired:
            print ("expired worker: %s" % address)
            self.queue.pop(address, None)

    def next(self):
        address, worker = self.queue.popitem(False)
        return address

local_live_interval = threading.local()

def worker_task(ident): #receive the request from the client or send the message to backend
    worker = zmq.Context().socket(zmq.DEALER)
    worker.identity = u"Worker-{}".format(ident).encode("ascii")
    worker.connect("tcp://localhost:5679")

    # Tell broker we're ready for work
    worker.send(PPP_READY)
    
    local_live_interval.liveness = HEARTBEAT_LIVENESS
    local_live_interval.interval = INTERVAL_INIT
    
    poll_worker = zmq.Poller() 
    poll_worker.register(worker,zmq.POLLIN)
    local_live_interval.heartbeat_timeat = time.time() + HEARTBEAT_INTERVAL

    while True:
        socks = dict(poll_worker.poll(HEARTBEAT_INTERVAL * 1000))  
        #frames = worker.recv_multipart()               # format:[b'client',b'',message_body]
        print("{}".format(worker.identity.decode("ascii")))
         
        if socks.get(worker) == zmq.POLLIN:
            frames = worker.recv_multipart()
            #print("worker gets:",frames)
            if not frames:
                break # Interrupted

            if len(frames) == 3:
                print ("I: Normal reply")
                image = Image.open(BytesIO(frames[2]))
                result = crnn_recognition(image, model)
                image.save("/home/cad488/test_images/"+ time.asctime(time.localtime(time.time()))+".jpg")
                worker.send_multipart([frames[0],b"",result.encode("ascii")])
                local_live_interval.liveness = HEARTBEAT_LIVENESS
            elif len(frames) == 1 and frames[0] == PPP_HEARTBEAT:
                print ("I: Queue heartbeat")
                local_live_interval.liveness = HEARTBEAT_LIVENESS
            else:
                print ("E: Invalid message: %s" % frames)
            local_live_interval.interval = INTERVAL_INIT
        else:
            local_live_interval.liveness -= 1
            if local_live_interval.liveness == 0:
                print ("W: Heartbeat failure, can't reach queue")
                print ("W: Reconnecting in %0.2fs…" % local_live_interval.interval)

                if local_live_interval.interval < INTERVAL_MAX:
                    local_live_interval.interval *= 2
                poll_worker.unregister(worker)
                worker.setsockopt(zmq.LINGER, 0)
                worker.close()
                worker = zmq.Context().socket(zmq.DEALER)
                worker.identity = u"Worker-{}".format(ident).encode("ascii")
                worker.connect("tcp://localhost:5679")
                worker.send(PPP_READY)
                local_live_interval.liveness = HEARTBEAT_LIVENESS
        if time.time() > local_live_interval.heartbeat_timeat:
            local_live_interval.heartbeat_timeat = time.time() + HEARTBEAT_INTERVAL
            print ("I: Worker heartbeat")
            worker.send(PPP_HEARTBEAT)

def main():
    """Load balancer main loop."""
    # Prepare context and sockets
    context = zmq.Context.instance()
    frontend = context.socket(zmq.ROUTER)
    frontend.bind(FRONTEND_HOST)
    backend = context.socket(zmq.ROUTER)
    backend.bind(BACKEND_HOST)

    # Start background tasks
    def start(task, *args):
        process = multiprocessing.Process(target=task, args=args)
        process.daemon = True
        process.start()
    for i in range(NBR_WORKERS):
        start(worker_task, i)

    # Initialize main loop state
    workers = WorkerQueue()
    poller = zmq.Poller()
    heartbeat_at =time.time() + HEARTBEAT_INTERVAL
    # Only poll for requests from backend until workers are available
    poller.register(backend, zmq.POLLIN)

    while True:
        sockets = dict(poller.poll(HEARTBEAT_INTERVAL * 1000))
        print("sockets:",sockets.get(backend))
        if backend in sockets:
            # Handle worker activity on the backend
            frames = backend.recv_multipart()
            print("get from frontend or worker:",frames)
            if not frames:
                break
            address  = frames[0]
            print("length socks:",len(workers.queue))
            print("workers queue:",workers.queue)
            if len(workers.queue) == 0:
               poller.register(frontend, zmq.POLLIN)
            workers.ready(Worker(address))
            msg = frames[1:]
            if len(msg) == 1:
                if msg[0] not in (PPP_READY, PPP_HEARTBEAT):
                    print("E: Invaild message from worker: %s" %msg)
            else:
                frontend.send_multipart(msg)
            if time.time() >= heartbeat_at:
                for worker in workers.queue:
                    #print("worker is :",worker)
                    msg = [worker, PPP_HEARTBEAT]
                    backend.send_multipart(msg)
                heartbeat_at = time.time() + HEARTBEAT_INTERVAL
                       
        if frontend in sockets:
            frames = frontend.recv_multipart()
            #print("get from client or backend:",frames)
            if not frames:
                break
            frames.insert(0,workers.next())
            backend.send_multipart(frames)
            if len(workers.queue) == 0:
                poller.unregister(frontend)
        
        workers.purge()
    
    # Clean up
    backend.close()
    frontend.close()
    context.term()


if __name__ == '__main__':
    
    # crnn network
    model = crnn.CRNN(32, 1, nclass, 256)
    #if torch.cuda.is_available():
        #model = model.cuda()
    print('loading pretrained model from {0}'.format(crnn_model_path))
    # 导入已经训练好的crnn模型
    model.load_state_dict(torch.load(crnn_model_path,map_location=torch.device('cpu')))
    main()
